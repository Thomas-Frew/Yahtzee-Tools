{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 19:33:39.091683: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-25 19:33:39.092271: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-25 19:33:39.095540: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-25 19:33:39.105368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732525419.119566  280281 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732525419.124086  280281 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 19:33:39.143809: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "import data_processing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"output_dataset.csv\"\n",
    "df = pd.read_csv(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ones</th>\n",
       "      <th>Twos</th>\n",
       "      <th>Threes</th>\n",
       "      <th>Fours</th>\n",
       "      <th>Fives</th>\n",
       "      <th>Sixes</th>\n",
       "      <th>Total</th>\n",
       "      <th>Bonus</th>\n",
       "      <th>3 of a Kind</th>\n",
       "      <th>4 of a Kind</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Mask</th>\n",
       "      <th>Bonus Mask</th>\n",
       "      <th>3 of a Kind Mask</th>\n",
       "      <th>4 of a Kind Mask</th>\n",
       "      <th>Full House Mask</th>\n",
       "      <th>Small Straight Mask</th>\n",
       "      <th>Large Straight Mask</th>\n",
       "      <th>Chance Mask</th>\n",
       "      <th>Yahtzee Mask</th>\n",
       "      <th>Score Mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1099 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ones   Twos  Threes  Fours  Fives  Sixes  Total  Bonus  3 of a Kind  \\\n",
       "0    -100.0 -100.0  -100.0 -100.0 -100.0 -100.0 -100.0 -100.0       -100.0   \n",
       "1    -100.0 -100.0  -100.0 -100.0 -100.0   18.0 -100.0 -100.0       -100.0   \n",
       "2    -100.0 -100.0  -100.0 -100.0 -100.0   18.0 -100.0 -100.0         25.0   \n",
       "3    -100.0 -100.0  -100.0   12.0 -100.0   18.0 -100.0 -100.0         25.0   \n",
       "4       4.0 -100.0  -100.0   12.0 -100.0   18.0 -100.0 -100.0         25.0   \n",
       "...     ...    ...     ...    ...    ...    ...    ...    ...          ...   \n",
       "1094    2.0 -100.0     9.0   16.0   20.0   18.0 -100.0 -100.0         27.0   \n",
       "1095    2.0 -100.0     9.0   16.0   20.0   18.0 -100.0 -100.0         27.0   \n",
       "1096    2.0    0.0     9.0   16.0   20.0   18.0   65.0   35.0         27.0   \n",
       "1097    2.0    0.0     9.0   16.0   20.0   18.0   65.0   35.0         27.0   \n",
       "1098    2.0    0.0     9.0   16.0   20.0   18.0   65.0   35.0         27.0   \n",
       "\n",
       "      4 of a Kind  ...  Total Mask  Bonus Mask  3 of a Kind Mask  \\\n",
       "0          -100.0  ...         1.0         1.0               1.0   \n",
       "1          -100.0  ...         1.0         1.0               1.0   \n",
       "2          -100.0  ...         1.0         1.0               0.0   \n",
       "3          -100.0  ...         1.0         1.0               0.0   \n",
       "4          -100.0  ...         1.0         1.0               0.0   \n",
       "...           ...  ...         ...         ...               ...   \n",
       "1094         29.0  ...         1.0         1.0               0.0   \n",
       "1095         29.0  ...         1.0         1.0               0.0   \n",
       "1096         29.0  ...         0.0         0.0               0.0   \n",
       "1097         29.0  ...         0.0         0.0               0.0   \n",
       "1098         29.0  ...         0.0         0.0               0.0   \n",
       "\n",
       "      4 of a Kind Mask  Full House Mask  Small Straight Mask  \\\n",
       "0                  1.0              1.0                  0.0   \n",
       "1                  1.0              1.0                  0.0   \n",
       "2                  1.0              1.0                  0.0   \n",
       "3                  1.0              1.0                  0.0   \n",
       "4                  1.0              1.0                  0.0   \n",
       "...                ...              ...                  ...   \n",
       "1094               0.0              1.0                  1.0   \n",
       "1095               0.0              1.0                  0.0   \n",
       "1096               0.0              1.0                  0.0   \n",
       "1097               0.0              0.0                  0.0   \n",
       "1098               0.0              0.0                  0.0   \n",
       "\n",
       "      Large Straight Mask  Chance Mask  Yahtzee Mask  Score Mask  \n",
       "0                     1.0          1.0           1.0         0.0  \n",
       "1                     1.0          1.0           1.0         0.0  \n",
       "2                     1.0          1.0           1.0         0.0  \n",
       "3                     1.0          1.0           1.0         0.0  \n",
       "4                     1.0          1.0           1.0         0.0  \n",
       "...                   ...          ...           ...         ...  \n",
       "1094                  0.0          0.0           1.0         0.0  \n",
       "1095                  0.0          0.0           1.0         0.0  \n",
       "1096                  0.0          0.0           1.0         0.0  \n",
       "1097                  0.0          0.0           1.0         0.0  \n",
       "1098                  0.0          0.0           0.0         0.0  \n",
       "\n",
       "[1099 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process dataset\n",
    "df = dp.add_headers(df)\n",
    "df = dp.trim_id(df)\n",
    "df = dp.mask_data(df)\n",
    "df = dp.impute_nans(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       271\n",
       "1       271\n",
       "2       271\n",
       "3       271\n",
       "4       271\n",
       "       ... \n",
       "1094    273\n",
       "1095    273\n",
       "1096    273\n",
       "1097    273\n",
       "1098    273\n",
       "Name: Score, Length: 1099, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset\n",
    "X, y = dp.split_xy(df)\n",
    "X_train, X_test, y_train, y_test = dp.split_train_test(X, y, 0.2)\n",
    "\n",
    "# Normalize data\n",
    "X_train = dp.scale_data(X_train, True)\n",
    "X_test = dp.scale_data(X_test, False)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 19:31:20.875532: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Deep Neural Network\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(shape=(31,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 255.7374 - val_loss: 243.9282\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.1165 - val_loss: 200.6959\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.9700 - val_loss: 109.8386\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 104.5580 - val_loss: 88.9701\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87.1115 - val_loss: 77.2534\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.0529 - val_loss: 67.8455\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5388 - val_loss: 61.8199\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8008 - val_loss: 56.4856\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.8595 - val_loss: 51.3568\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44.8970 - val_loss: 46.7370\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.4900 - val_loss: 45.3536\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.2728 - val_loss: 42.4489\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.4566 - val_loss: 40.9711\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 37.6337 - val_loss: 38.6113\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.9610 - val_loss: 37.0812\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.3404 - val_loss: 34.9514\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.3968 - val_loss: 35.8123\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.6917 - val_loss: 35.1916\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.8362 - val_loss: 32.8849\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.2280 - val_loss: 34.3166\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.7932 - val_loss: 31.9473\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.0254 - val_loss: 31.7877\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.5232 - val_loss: 31.5501\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.9936 - val_loss: 30.9165\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.6236 - val_loss: 31.0686\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.1668 - val_loss: 29.9562\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.7709 - val_loss: 31.6738\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.0167 - val_loss: 31.1439\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.4649 - val_loss: 29.4438\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3235 - val_loss: 29.3638\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.8115 - val_loss: 31.0234\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.0793 - val_loss: 29.4520\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.5059 - val_loss: 30.8350\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.0608 - val_loss: 29.2794\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.7143 - val_loss: 31.0473\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0665 - val_loss: 30.6474\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.1312 - val_loss: 30.2663\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.2525 - val_loss: 30.1959\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.0758 - val_loss: 30.5504\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.7032 - val_loss: 28.7872\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.3969 - val_loss: 30.2054\n",
      "Epoch 42/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.6210 - val_loss: 29.7094\n",
      "Epoch 43/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.8923 - val_loss: 29.7806\n",
      "Epoch 44/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.3354 - val_loss: 29.1562\n",
      "Epoch 45/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.5583 - val_loss: 29.9570\n",
      "Epoch 46/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.9417 - val_loss: 29.9190\n",
      "Epoch 47/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.8456 - val_loss: 30.2731\n",
      "Epoch 48/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.2336 - val_loss: 29.8401\n",
      "Epoch 49/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.8188 - val_loss: 30.3253\n",
      "Epoch 50/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.2572 - val_loss: 29.6317\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44.8802 \n",
      "Test Loss: 42.41960144042969\n"
     ]
    }
   ],
   "source": [
    "# Test loss\n",
    "test_loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Data:  [2.0, 8.0, 9.0, 12.0, 15.0, -100.0, -100.0, -100.0, 16.0, 14.0, 25.0, 30.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Prediction:  194.85019\n",
      "Actual:  205\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Make predictions on the test data, print random\n",
    "random_index = random.randint(0, len(X_test) - 1)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Data: \", list(X_test.iloc[random_index]))\n",
    "print(\"Prediction: \", predictions[random_index][0]) \n",
    "print(\"Actual: \", y_test.iloc[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n"
     ]
    }
   ],
   "source": [
    "h5_filename = \"output_model.keras\"\n",
    "model.save(h5_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
